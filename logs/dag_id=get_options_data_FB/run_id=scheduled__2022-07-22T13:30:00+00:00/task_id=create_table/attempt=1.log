[2022-07-22 14:08:38,747] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [queued]>
[2022-07-22 14:08:38,762] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [queued]>
[2022-07-22 14:08:38,762] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-07-22 14:08:38,762] {taskinstance.py:1377} INFO - Starting attempt 1 of 2
[2022-07-22 14:08:38,763] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-07-22 14:08:38,787] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): create_table> on 2022-07-22 13:30:00+00:00
[2022-07-22 14:08:38,793] {standard_task_runner.py:52} INFO - Started process 367 to run task
[2022-07-22 14:08:38,797] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'get_options_data_FB', 'create_table', 'scheduled__2022-07-22T13:30:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/open_options.py', '--cfg-path', '/tmp/tmprann620w', '--error-file', '/tmp/tmpr4h4sobw']
[2022-07-22 14:08:38,798] {standard_task_runner.py:80} INFO - Job 6: Subtask create_table
[2022-07-22 14:08:38,871] {task_command.py:371} INFO - Running <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [running]> on host 64ccb97fbb2c
[2022-07-22 14:08:38,944] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=chrischow
AIRFLOW_CTX_DAG_ID=get_options_data_FB
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2022-07-22T13:30:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-22T13:30:00+00:00
[2022-07-22 14:08:38,968] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/open_options.py", line 68, in create_table
    """)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 204, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `postgres_optionsdata` isn't defined
[2022-07-22 14:08:38,973] {taskinstance.py:1420} INFO - Marking task as UP_FOR_RETRY. dag_id=get_options_data_FB, task_id=create_table, execution_date=20220722T133000, start_date=20220722T140838, end_date=20220722T140838
[2022-07-22 14:08:38,991] {standard_task_runner.py:97} ERROR - Failed to execute job 6 for task create_table (The conn_id `postgres_optionsdata` isn't defined; 367)
[2022-07-22 14:08:39,008] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-07-22 14:08:39,146] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-07-22 14:11:45,194] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [queued]>
[2022-07-22 14:11:45,214] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [queued]>
[2022-07-22 14:11:45,216] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-07-22 14:11:45,216] {taskinstance.py:1377} INFO - Starting attempt 1 of 2
[2022-07-22 14:11:45,217] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-07-22 14:11:45,245] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): create_table> on 2022-07-22 13:30:00+00:00
[2022-07-22 14:11:45,253] {standard_task_runner.py:52} INFO - Started process 366 to run task
[2022-07-22 14:11:45,258] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'get_options_data_FB', 'create_table', 'scheduled__2022-07-22T13:30:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/open_options.py', '--cfg-path', '/tmp/tmpxdf4uzrn', '--error-file', '/tmp/tmpnb2csjzm']
[2022-07-22 14:11:45,259] {standard_task_runner.py:80} INFO - Job 3: Subtask create_table
[2022-07-22 14:11:45,333] {task_command.py:371} INFO - Running <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [running]> on host 3e4d0946f42d
[2022-07-22 14:11:45,421] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=chrischow
AIRFLOW_CTX_DAG_ID=get_options_data_FB
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2022-07-22T13:30:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-22T13:30:00+00:00
[2022-07-22 14:11:45,434] {base.py:68} INFO - Using connection ID 'postgres_optionsdata' for task execution.
[2022-07-22 14:11:45,439] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/open_options.py", line 68, in create_table
    """)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 204, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.19.0.2), port 5432 failed: FATAL:  password authentication failed for user "***"

[2022-07-22 14:11:45,456] {taskinstance.py:1420} INFO - Marking task as UP_FOR_RETRY. dag_id=get_options_data_FB, task_id=create_table, execution_date=20220722T133000, start_date=20220722T141145, end_date=20220722T141145
[2022-07-22 14:11:45,479] {standard_task_runner.py:97} ERROR - Failed to execute job 3 for task create_table (connection to server at "postgres" (172.19.0.2), port 5432 failed: FATAL:  password authentication failed for user "***"
; 366)
[2022-07-22 14:11:45,509] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-07-22 14:11:45,590] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-07-22 14:15:02,718] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [queued]>
[2022-07-22 14:15:02,733] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [queued]>
[2022-07-22 14:15:02,735] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-07-22 14:15:02,736] {taskinstance.py:1377} INFO - Starting attempt 1 of 2
[2022-07-22 14:15:02,736] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-07-22 14:15:02,756] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): create_table> on 2022-07-22 13:30:00+00:00
[2022-07-22 14:15:02,761] {standard_task_runner.py:52} INFO - Started process 366 to run task
[2022-07-22 14:15:02,765] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'get_options_data_FB', 'create_table', 'scheduled__2022-07-22T13:30:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/open_options.py', '--cfg-path', '/tmp/tmpiy7a_5y2', '--error-file', '/tmp/tmps1ozkl8c']
[2022-07-22 14:15:02,768] {standard_task_runner.py:80} INFO - Job 4: Subtask create_table
[2022-07-22 14:15:02,853] {task_command.py:371} INFO - Running <TaskInstance: get_options_data_FB.create_table scheduled__2022-07-22T13:30:00+00:00 [running]> on host 6ca3a31f58ff
[2022-07-22 14:15:02,942] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=chrischow
AIRFLOW_CTX_DAG_ID=get_options_data_FB
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2022-07-22T13:30:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-22T13:30:00+00:00
[2022-07-22 14:15:02,956] {base.py:68} INFO - Using connection ID 'postgres_optionsdata' for task execution.
[2022-07-22 14:15:02,964] {dbapi.py:231} INFO - Running statement: 
CREATE TABLE IF NOT EXISTS FB (
    put_call VARCHAR(5) NOT NULL,
    symbol VARCHAR(32) NOT NULL,
    description VARCHAR(64) NOT NULL,
    bid DOUBLE PRECISION,
    ask DOUBLE PRECISION,
    last DOUBLE PRECISION,
    bid_size INTEGER,
    ask_size INTEGER,
    last_size INTEGER,
    high_price DOUBLE PRECISION,
    low_price DOUBLE PRECISION,
    open_price DOUBLE PRECISION,
    close_price DOUBLE PRECISION,
    total_volume INTEGER,
    quote_time BIGINT,
    volatility DOUBLE PRECISION,
    delta DOUBLE PRECISION,
    gamma DOUBLE PRECISION,
    theta DOUBLE PRECISION,
    vega DOUBLE PRECISION,
    rho DOUBLE PRECISION,
    open_interest INTEGER,
    time_value DOUBLE PRECISION,
    theoretical_value DOUBLE PRECISION,
    strike_price DOUBLE PRECISION,
    expiration_date BIGINT,
    dte INTEGER,
    PRIMARY KEY (symbol, quote_time)
)
, parameters: None
[2022-07-22 14:15:02,971] {python.py:173} INFO - Done. Returned value was: None
[2022-07-22 14:15:02,996] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=get_options_data_FB, task_id=create_table, execution_date=20220722T133000, start_date=20220722T141502, end_date=20220722T141502
[2022-07-22 14:15:03,057] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-07-22 14:15:03,126] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
